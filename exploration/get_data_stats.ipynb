{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from spacy.lang.en import English\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.attrs import ORTH, NORM\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_suffix_regex, compile_infix_regex\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset_path = '../src/loaders'\n",
    "sys.path.append(dataset_path)\n",
    "from CRD3Dataset import CRD3Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cfg_path = '../src/loaders/CRD3Dataset_all.yaml'\n",
    "dataset = CRD3Dataset(cfg_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "18378"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chunks = len(list(dataset._iter_chunk()))\n",
    "n_chunks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def get_tokens():\n",
    "    # Extract tokens from all the data\n",
    "    nlp = English()\n",
    "    suffixes = nlp.Defaults.suffixes + [r'''--$''', r'''\\)$''', r''':$''', r'''\\]$''', r'''\\-$''']\n",
    "    prefixes = nlp.Defaults.prefixes + [r'''^--''', r'''^\\(''', r'''^\\[''', r'''^\\-''']\n",
    "    infixes = nlp.Defaults.infixes + [\n",
    "        r'''\\(''', r'''\\)''', r'''--''', r'''\"''', r'''\\[''', r'''\\]''',\n",
    "        r'''(?<=[dmsu123])x(?=[0-9]{1,3})''']  # Last one is for episode numbers, e.g. 1x24, sx65, e3x01...\n",
    "    suffix_regex = compile_suffix_regex(suffixes)\n",
    "    prefix_regex = compile_prefix_regex(prefixes)\n",
    "    infix_regex = compile_infix_regex(infixes)\n",
    "    nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "    nlp.tokenizer.prefix_search = prefix_regex.search\n",
    "    nlp.tokenizer.infix_finditer = infix_regex.finditer\n",
    "    tokenizer: Tokenizer = nlp.tokenizer\n",
    "\n",
    "    tokens = defaultdict(lambda: 0)\n",
    "    speaker_tokens = defaultdict(lambda: 0)\n",
    "\n",
    "    # CRD3 Data\n",
    "    for speaker_strings, utt_strings, summary_string in tqdm(dataset._iter_chunk(), total=n_chunks):\n",
    "        for token in tokenizer(summary_string.lower()):\n",
    "            tokens[token.text] += 1\n",
    "        for token in (t for s in speaker_strings for t in tokenizer(s.lower())):\n",
    "            speaker_tokens[token.text] += 1\n",
    "        for token in (t for s in utt_strings for t in tokenizer(s.lower())):\n",
    "            tokens[token.text] += 1\n",
    "\n",
    "    # Campaign 3 ep. 1\n",
    "    with open('../data/C3E001.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                speaker_idx = line.index(':')\n",
    "            except Exception as e:\n",
    "                print(line)\n",
    "                raise e\n",
    "            speaker_strings = line[:speaker_idx].lower()\n",
    "            speaker_strings = speaker_strings.replace('and', '')  # Remove 'and' from speakers\n",
    "            utt_strings = line[speaker_idx + 1:].lower()\n",
    "\n",
    "            for token in (t for t in tokenizer(speaker_strings)):\n",
    "                speaker_tokens[token.text] += 1\n",
    "            for token in (t for t in tokenizer(utt_strings)):\n",
    "                tokens[token.text] += 1\n",
    "\n",
    "    # Episode blurbs from the fandom\n",
    "    blurb_df = pd.read_csv('../data/CR_blurbs.tsv', sep='\\t')\n",
    "    for token in (t for s in blurb_df['summary'].values.tolist() for t in tokenizer(s.lower())):\n",
    "            tokens[token.text] += 1\n",
    "\n",
    "    return list(speaker_tokens.keys()), list(tokens.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18378/18378 [00:46<00:00, 396.73it/s]\n"
     ]
    }
   ],
   "source": [
    "spkr_strings, strings = get_tokens()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "76"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spkr_strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "['matt',\n 'travis',\n 'marisha',\n 'taliesin',\n 'sam',\n 'orion',\n 'liam',\n 'laura',\n 'zac',\n 'all',\n '-',\n 'producer',\n 'crew',\n 'ashley',\n 'wil',\n 'ivan',\n 'becca',\n 'ify',\n 'hector',\n 'lucas',\n 'ahsley',\n 'computer',\n 'generated',\n 'voice',\n 'erika',\n 'kai',\n 'jore',\n 'mary',\n 'felicia',\n 'ryan',\n 'will',\n 'steve',\n 'darin',\n 'kit',\n 'alec',\n 'offscreen',\n 'chris',\n 'perkins',\n 'hardwick',\n 'patrick',\n 'rothfuss',\n 'sound',\n 'iphone',\n 'brian',\n 'denise',\n 'amandine',\n 'screen',\n 'noelle',\n 'jon',\n 'willmott',\n 'audience',\n 'member',\n 'joe',\n 'khary',\n 'joel',\n 'toy',\n 'in',\n 'bag',\n 'mark',\n 'babs',\n 'sumalee',\n 'max',\n 'cast',\n 'amy',\n 'eric',\n 'cameraman',\n 'yuri',\n 'yasmine',\n 'sean',\n 'allison',\n 'annet',\n 'joey',\n 'lenore',\n 'deborah',\n ' ',\n 'robbie']"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spkr_strings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "37703"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "['7:00pm',\n ':',\n '3:00',\n '4:00',\n '7:00',\n '1:30am',\n '12:30',\n 'grog:',\n 'vex:',\n 'vax:',\n 'pike:',\n 'scanlan:',\n 'tiberius:',\n 'percy:',\n 'keyleth:',\n 'clarota:',\n 'kima:',\n '11:00',\n '12:15',\n '10:00',\n '2:00',\n '9:30pm',\n '11:30',\n '8:30',\n '9:00',\n '11:00pm',\n '5:30',\n '2:30',\n '4:30',\n '6:00',\n '8:00',\n '9:30',\n '10:30',\n '6:30',\n '4:30pm',\n '13:00',\n '1:00',\n '19:00',\n '1:30',\n '20:16',\n '33:14',\n '8:00pm',\n '):',\n '7:00pm-10:00pm',\n '4:00am',\n '8:00am',\n '9:00pm',\n '5:00',\n '2:22:43',\n '4:24',\n '5:00pm',\n '9:00am',\n 'http://www.geekandsundry.com/crsurvey',\n '12:00',\n '10:30am',\n '6:00am',\n '12:40',\n '2:00am',\n '7:30',\n '10:00pm',\n 'art:@tessfowler',\n '11:00am',\n '11:30am',\n '2:00pm',\n '8:30pm',\n '10:00am',\n '7:00am',\n '9:14',\n '3:00am',\n '1:00pm',\n 'taliesin:',\n 'matt:',\n 'lorenzo:',\n '6:30pm',\n '6:00pm',\n '7:15',\n 'caduceus:',\n 'jester:',\n 'beau:',\n 'fjord:',\n 'together:',\n 'caleb:',\n 'nott:',\n 'saying:',\n '7:30am',\n '7:30pm',\n 'http://bit.ly/wbdnd',\n '5:00am']"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in strings if ':' in s]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "['[', ']']"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in strings if ']' in s or '[' in s]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "['.',\n '...',\n 'air.the',\n 'a.',\n 'r.',\n '..',\n 'i.',\n 'd.',\n 'tabletopday.com',\n 'angelfire.tabletopday.com',\n 'j.',\n 'geekandsundry.com',\n 'redbubble.com',\n '1.50',\n 'l.a',\n 'b.',\n 't.',\n '826la.com',\n 'n.',\n 'encounter.',\n 'fantasycoinhq.com',\n 'joxer.',\n 'u.',\n 'critrole.com',\n 'www.critrole.com',\n 'y.',\n 'l.',\n 'teespring.com/critical-role',\n 'yeah.there',\n '....',\n 'x.',\n '1.5squareinches',\n 'i.e.',\n 'w.',\n 'k.',\n 'p.s',\n 'g.e',\n 'a.k.a',\n 'geekandsundry.com/shows/critical-role',\n '4.2',\n 'm.',\n 'z.',\n 'i.o.u',\n 's.h.i.ts',\n 'others.',\n '23.89',\n '111.11',\n 'wattpad.com',\n 'contract.',\n 'e.',\n 'feliciadaybook.com',\n 'room.people',\n '82.60',\n '43.21',\n '60.39',\n '55.55',\n 'nextgreatgamingchallenge.com',\n 'nextgreatgamechallenge.com',\n 'welovefine.com',\n '6.2',\n '6.4',\n '6.5',\n '4.3',\n 'green.',\n '5.1',\n 'a.m.',\n 'v.',\n 'brin.',\n '9.5k',\n '13.37',\n '35.10',\n 'twitch.tv/nerdist',\n '0.3',\n 'wyrmwoodgaming.com',\n 'etc.—but',\n 'geekandsundry.com/finditonthatsitesomewhere',\n 'www.tonsofshit.com',\n 'g.',\n 'shapeways.com',\n 'h.',\n '1.2',\n 'boonzyarts.com',\n 'vs.',\n 's.h.i.t.s',\n '1.000',\n '3.5',\n 'l.m',\n '.percy',\n '1.1',\n 'awesome.that',\n 'five.19',\n 'twitch.tv/wizardworld',\n '.mov',\n '.mp4',\n 'preferredpartner@geekandsundry.com',\n 'p.t',\n 'by.',\n 'www.lootcrate.com/criticalrole',\n 'lootcrate.com/criticalrole',\n 'shirt.',\n 'www.loot',\n 'crate.com/criticalrole',\n 'twitch.tv/geekandsundry',\n 'lootcrate.com/criticalroledx',\n 'subscription.',\n 'www.lootcrate.com/criticalroledx',\n 's.',\n 'worldbuilders.org',\n 'iam8bit.com',\n 'sorry.',\n 'c.',\n 'backblaze.com/criticalrole',\n 'geekandsundry.com/crlivegencon16',\n 'backblaze.com',\n 'service.</div',\n 'lootcrate.com/crates',\n 'seeking.',\n 'lootcrate.com/',\n '1.5',\n '266.67',\n 'leonis.',\n 'alphainvite.com',\n 'o.',\n 'talksmachina@gmail.com',\n 'lootcrate.com/vivathordak',\n '0.1',\n 'p.o',\n '9.5',\n 'l.e.b',\n 'p.f',\n 'f.',\n 'lootcrate.com/keys',\n 'nerdist.com/powerrangersgiveaway',\n 't.d',\n '5.9',\n '6.3',\n 'fundly.com/we-love-amandine/',\n 'fundly.com/we-love-amandine',\n 'projectalpha.com',\n 'lootcrate.com',\n 'geekandsundry.com/crsurvey',\n 'www.tabletopday.com',\n 'http://www.geekandsundry.com/crsurvey',\n 'd.t',\n '2.0',\n 'submit@talksmachina.com',\n 'wyrmwoodgaming.com/criticalrole',\n '3.2',\n 'bit.ly/crquidd',\n 'paizo.com',\n 'bit.ly/magicrole',\n 'geekandsundry.com/artbook',\n 'k.o',\n 'u.s',\n 'j.j',\n 'a.w.a',\n 'd.a.r.e',\n 'g.i',\n 'feathers.',\n '3.0',\n 'dndbeyond.com',\n 'bros./monolith',\n 't.j',\n 'd.p',\n 'a.c',\n 'p.d',\n 'b.o.-y',\n 'm.o',\n 'www.dndbeyond.com',\n 'careers.com',\n 'section.that',\n 'w.c',\n 'www.twitch.tv/dndbeyond',\n 'twitch.tv/dndbeyond',\n 'bit.ly/dndios',\n 'bit.ly/dndandroid',\n 'bit.ly',\n 'facebook.com/dndbeyond',\n 'twitter.com',\n 'wheniscriticalrole.com',\n 'c2e2.com',\n 'farcry.com',\n 'nerdist.com',\n 'youtube.com/nerdist',\n 'pacificrimtickets.com',\n 'endeavor.',\n '13.50',\n 'co.',\n 'f.a.t.a.l',\n 'cloudy.the',\n 'came.',\n 'versusevil.com/criticalrole',\n 'd.c',\n '826la.org',\n 'm.t',\n '826la.org/criticalrole',\n 'www.826la.org/criticalrole',\n 'beacon.',\n 'nein.',\n 'declared.',\n 'over.',\n 'a.s.a.p',\n 'dnd.wizards.com/some',\n 'patreon.com/kiframe',\n 'twitch.tv/yogscast',\n 'dmsguild.com',\n 'b.e.f',\n 'babsbabsbabs.com',\n 'jasoncharlesmiller.com',\n 'twitch.tv/webdm',\n 'twitch.tv/criticalrole',\n 'twitch.tv/webdm(or',\n 'twitter.com/dndbeyond',\n 'shop.critrole.com',\n 'while.',\n 'k.i.t',\n 'p.o.v',\n 'youtube.com/criticalrole',\n 'versesevil.com/criticalrole',\n 'shepherds.',\n '17.it',\n 'critrole.com/dwarvenforge',\n 'm.m',\n 'hate.',\n 'criticalrole.com',\n 'therookandtheraven.com/criticalrole',\n 'give.classy.org/teamherter',\n 'home.',\n 'bit.the',\n 'action.you',\n 'p.m.',\n 'critrole.com/events',\n '0.2346',\n 'dndbeyond.com/promotions/platinum',\n 'beadleandgrimms.com',\n 'beadleandgrimms.com/spoilers',\n 'chamber.in',\n 'good.16',\n 'p.',\n 'critrole.com/osd',\n 't.k.o',\n 'dndbeyond.com/marketplace',\n 'twitch.tv/get-fooked-ya-clatty-radge-wee-shite',\n 'center.in',\n 'otherwise.',\n 'shop.critrole.co.uk',\n 'reef.',\n 'cup.',\n 'unplugged.paxsite.com',\n 'http://bit.ly/wbdnd',\n 'bit.ly/wbdnd',\n 'reckless.15',\n 'it.',\n 'dndbeyond.com/criticalrole',\n 'chamber.',\n 'adventure.']"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in strings if '.' in s]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "['-',\n '--',\n 'type-0',\n 'mid-2000s',\n 'fate-0',\n 'teespring.com/critical-role',\n 'k-12th',\n 'b-52s',\n 'geekandsundry.com/shows/critical-role',\n \"vex-'ah\",\n '-y',\n '-ing',\n 'by-10',\n 'by-20',\n 'mid-20s',\n 't-1000',\n 'level-3',\n 'level-4',\n 'level-1',\n 'level-6',\n 'level-5',\n 'level-2',\n 'mid-40s',\n 'mid-900s',\n 'z-114',\n '20th-21st',\n '7:00pm-10:00pm',\n \"o'-wisp\",\n 'of-12',\n 'but-—when',\n 'mid-60s',\n 'c-20',\n 'fundly.com/we-love-amandine/',\n 'fundly.com/we-love-amandine',\n \"killed'-type\",\n 'c-3po',\n '-type',\n 't-2',\n '8th-11th',\n 'i-9',\n 't-800',\n 'level-7',\n 'b.o.-y',\n 'late-30s',\n '-like',\n 'ass-20s',\n \"o'-wisps\",\n 'mid-30s',\n '-and',\n 'by-15',\n 'fucking-',\n '-you',\n 'twitch.tv/get-fooked-ya-clatty-radge-wee-shite',\n 'mid-80s']"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in strings if '-' in s]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "CRD3_vocab = Vocab(strings=strings)\n",
    "CRD3_spkr_vocab = Vocab(strings=spkr_strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "(37703, 76)"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CRD3_vocab), len(CRD3_spkr_vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "'matt'"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRD3_vocab.strings[11113032409865315573]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "11113032409865315573"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRD3_spkr_vocab.strings['matt']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "((37703,), (76,))"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_idxs = np.array([CRD3_vocab.strings[s] for s in strings])\n",
    "spkr_hash_idxs = np.array([CRD3_spkr_vocab.strings[s] for s in spkr_strings])\n",
    "hash_idxs.shape, spkr_hash_idxs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "np.save('../data/CRD3_vocab_hash_idxs.npy', hash_idxs)\n",
    "np.save('../data/CRD3_vocab_spkr_hash_idxs.npy', spkr_hash_idxs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "CRD3_vocab.to_disk('../data/CRD3_vocab')\n",
    "CRD3_spkr_vocab.to_disk('../data/CRD3_spkr_vocab')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
